# About TinyExplorer FaceDetectionApp

## About the Project

TinyExplorer FaceDetectionApp is a desktop application designed for developmental research, providing robust face detection capabilities using state-of-the-art YOLO and RetinaFace models. The app enables researchers to efficiently process large volumes of images and videos, extracting face detection data for analysis.

## Copyright & Attribution

**Â© Cardiff Babylab**

### Project Team

- **Concept and Project Management:** Teodor Nikolov & Hana D'Souza
- **Lead Development and Implementation:** Tamas Foldes
- **Code Contributions:** Ziye Zhang & Teodor Nikolov

## Research Applications

This application was developed to support developmental psychology research at Cardiff Babylab, enabling:

- Automated face detection in experimental recordings
- Batch processing of research data
- Standardized data extraction for statistical analysis
- Cross-platform deployment for research teams

## Technical Stack

The application combines modern web technologies with machine learning frameworks:

- **Frontend:** React with TypeScript
- **Desktop Framework:** Electron
- **Backend:** Python with Flask
- **Machine Learning:** YOLO (PyTorch) and RetinaFace (TensorFlow)
- **Cross-platform:** Windows, macOS, and Linux support

## License

This project is released under the MIT License. See the [LICENSE](https://github.com/cardiff-babylab/tinyexplorer-facedetectionapp/blob/master/LICENSE.txt) file for details.

## Acknowledgments

Special thanks to the Cardiff Babylab team and all researchers who provided feedback and testing during development.

## Contact

For questions about the application or research collaborations, please contact the Cardiff Babylab team.

---

## Funding

This work was supported by a James S. McDonnell Foundation (JSMF) Opportunity Award (https://doi.org/10.37717/2022-3711) and a UKRI Future Leaders Fellowship (MR/X032922/1) awarded to HD.

---

*TinyExplorer FaceDetectionApp - Advancing developmental research through innovative technology*